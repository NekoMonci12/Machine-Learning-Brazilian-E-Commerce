# -*- coding: utf-8 -*-
"""ML_Muhammad Tamir.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DASn_ULg6Xo0-nWWp4-rJ7JNELiJYsTP

# Proyek Analisis Data: Brazilian E-Commerce Public
- **Nama:** Muhammad Tamir

## Menentukan Pertanyaan Bisnis

- Negara bagian (State) mana di Brazil yang memiliki konsentrasi pelanggan tertinggi, dan bagaimana distribusi total pendapatan (revenue) di antara negara bagian tersebut?
- Apakah terdapat korelasi antara lama waktu pengiriman (delivery time) dengan skor ulasan (review score) yang diberikan oleh pelanggan?

## Import Semua Packages/Library yang Digunakan
"""

import os
import re
import unicodedata
import kagglehub
from kagglehub import KaggleDatasetAdapter
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""## Data Wrangling

### Gathering Data

#### Setup Kaggle
"""

dataset_path = kagglehub.dataset_download("olistbr/brazilian-ecommerce")

files = [
    f for f in os.listdir(dataset_path)
    if f.endswith(".csv")
]

data = {}

for file_path in files:
    key = file_path.removesuffix(".csv")

    df = kagglehub.dataset_load(
        KaggleDatasetAdapter.PANDAS,
        "olistbr/brazilian-ecommerce",
        file_path,
    )

    data[key] = df

print("\n" + "="*56)
print(f"TOTAL DATASET DIMUAT: {len(data)}")
print("="*56)

for i, name in enumerate(sorted(data.keys()), 1):
    row_count = len(data[name])
    print(f"{i}. {name:<35} | {row_count:>9,} baris")

print("="*56)

"""**Insight:**
- xxx
- xxx

#### Setup City & State Mapping
"""

state_mapping = {
    "acre": "AC",
    "alagoas": "AL",
    "amapa": "AP",
    "amazonas": "AM",
    "bahia": "BA",
    "ceara": "CE",
    "distrito federal":"DF",
    "espirito santo": "ES",
    "goias": "GO",
    "maranhao": "MA",
    "mato grosso": "MT",
    "mato grosso do sul": "MS",
    "minas gerais": "MG",
    "para": "PA",
    "paraiba": "PB",
    "parana": "PR",
    "pernambuco": "PE",
    "piaui": "PI",
    "rio de janeiro": "RJ",
    "rio grande do norte": "RN",
    "rio grande do sul": "RS",
    "rondonia": "RO",
    "roraima": "RR",
    "santa catarina": "SC",
    "sao paulo": "SP",
    "sergipe": "SE",
    "tocantins": "TO"
}

"""### Assessing Data

#### Dataset Declaration
"""

customers = data["olist_customers_dataset"]
geolocation = data["olist_geolocation_dataset"]
order_item = data["olist_order_items_dataset"]
order_payment = data["olist_order_payments_dataset"]
order_review = data["olist_order_reviews_dataset"]
orders = data["olist_orders_dataset"]
products = data["olist_products_dataset"]
sellers = data["olist_sellers_dataset"]
product_category = data["product_category_name_translation"]

"""#### Dataset Function

##### Product Function
"""

def get_product_category(product_id, translate=False):
    category_series = products[products['product_id'] == product_id]['product_category_name']
    if not category_series.empty:
        category = category_series.values[0]
        if translate and 'product_category_name_translation' in data:
            translation = product_category[product_category['product_category_name'] == category]['product_category_name_english']
            if not translation.empty:
                return translation.values[0]

        return category
    else:
        return "Product ID tidak ditemukan"

"""#### Assessing Data Result

**Insight:**
- xxx
- xxx

### Cleaning Data

#### Functions

##### Cleaning Utils
"""

def normalize_unicode(text):
    if isinstance(text, str):
        return unicodedata.normalize("NFD", text)
    return text

def clean_brazilian_cities(text):
    if isinstance(text, str):
        text = text.replace('£', 'a')
        text = normalize_unicode(text)
        text = text.encode('ascii', 'ignore').decode("utf-8")
        text = re.sub(r'[^a-zA-Z\s]', '', text)

        return text.lower().strip()
    return text

def remove_duplicates_data(df, subset_columns):
    duplicate_count = df.duplicated(subset=subset_columns).sum()
    df_cleaned = df.drop_duplicates(subset=subset_columns, keep='first').copy()

    print(f"--- Laporan Pembersihan Duplikasi ---")
    print(f"Total baris awal      : {len(df)}")
    print(f"Jumlah duplikat literal: {duplicate_count}")
    print(f"Total baris sekarang  : {len(df_cleaned)}")
    print(f"-------------------------------------")

    return df_cleaned

def remove_mismatched_data(df_target, col_target, df_ref, col_ref):
    valid_values = df_ref[col_ref].unique()
    initial_count = len(df_target)
    df_cleaned = df_target[df_target[col_target].isin(valid_values)].copy()
    removed_count = initial_count - len(df_cleaned)

    print(f"--- Laporan Pembersihan Integritas ---")
    print(f"Dataset Target       : {initial_count} baris")
    print(f"Data tidak ditemukan : {removed_count} baris dihapus")
    print(f"Dataset Akhir        : {len(df_cleaned)} baris")
    print(f"---------------------------------------")

    return df_cleaned

def remove_null_rows(df, subset_columns):
    initial_count = len(df)
    df_cleaned = df.dropna(subset=subset_columns, how='any').copy()
    removed_count = initial_count - len(df_cleaned)

    print(f"--- Laporan Penanganan Missing Value ---")
    print(f"Dataset             : {initial_count} baris")
    print(f"Baris dengan null    : {removed_count} baris dihapus")
    print(f"Dataset Bersih      : {len(df_cleaned)} baris")
    print(f"----------------------------------------")

    return df_cleaned

"""##### City & State Validation"""

geo_reference = customers[['customer_city', 'customer_state']].drop_duplicates()
def check_location(city=None, state=None):
    if city: city = clean_brazilian_cities(city)
    if state: state = state.upper()

    if city and state:
        exists = not geo_reference[(geo_reference['customer_city'] == city) &
                                   (geo_reference['customer_state'] == state)].empty
        return exists

    elif city:
        states = geo_reference[geo_reference['customer_city'] == city]['customer_state'].unique()
        return f"{list(states)}" if len(states) > 0 else "Kota tidak ditemukan."

    elif state:
        cities = geo_reference[geo_reference['customer_state'] == state]['customer_city'].unique()
        return f"{list(cities[:5])}" if len(cities) > 0 else "State tidak ditemukan."

"""##### Date & Time Utils"""

def convert_to_datetime(df, column_name):
    df[column_name] = pd.to_datetime(df[column_name], errors='coerce')

    return df

"""#### Alter Format

##### Date & Time String To Datetime
"""

orders = convert_to_datetime(orders, 'order_purchase_timestamp')
orders = convert_to_datetime(orders, 'order_approved_at')
orders = convert_to_datetime(orders, 'order_delivered_carrier_date')
orders = convert_to_datetime(orders, 'order_delivered_customer_date')
orders = convert_to_datetime(orders, 'order_estimated_delivery_date')

"""#### Cleaning Process

##### Customers Dataset
"""

remove_duplicates_data(customers, ['customer_unique_id'])

"""##### Product Dataset"""

remove_null_rows(products, ["product_category_name"])

"""##### Order Dataset"""

remove_mismatched_data(order_item, 'order_id', orders, 'order_id')

remove_mismatched_data(order_payment, 'order_id', orders, 'order_id')

remove_mismatched_data(order_review, 'order_id', orders, 'order_id')

remove_mismatched_data(order_item, 'product_id', products, 'product_id')

"""##### Cleaning Results

**Insight:**
- xxx
- xxx

## Exploratory Data Analysis (EDA)

### Functions
"""

def top_data(df, n=5):
    return df.head(n)

"""### Statistik Deskriptif

#### Functions
"""

def dataset_summary(dataframes: dict):
    summary = []
    for name, df in dataframes.items():
        if df is None:
            summary.append({
                "dataset": name,
                "rows": 0,
                "columns": 0,
                "status": "NOT LOADED"
            })
        else:
            summary.append({
                "dataset": name,
                "rows": df.shape[0],
                "columns": df.shape[1],
                "status": "OK"
            })

    return pd.DataFrame(summary)

def orders_datetime_ranges(orders_df):
    datetime_cols = [
        "order_purchase_timestamp",
        "order_approved_at",
        "order_delivered_carrier_date",
        "order_delivered_customer_date",
        "order_estimated_delivery_date"
    ]

    summary = []

    for col in datetime_cols:
        temp = pd.to_datetime(orders_df[col], errors='coerce')

        summary.append({
            "column": col,
            "start_date": temp.min(),
            "end_date": temp.max(),
            "missing_pct": round(temp.isna().mean() * 100, 2)
        })

    return pd.DataFrame(summary)

def order_delivery_summary(orders_df):
    data = {
        "stage": [
            "Approved",
            "Delivered to Carrier",
            "Delivered to Customer"
        ],
        "order_count": [
            orders_df['order_approved_at'].notna().sum(),
            orders_df['order_delivered_carrier_date'].notna().sum(),
            orders_df['order_delivered_customer_date'].notna().sum()
        ]
    }
    return pd.DataFrame(data)

def order_status_summary(orders_df):
    return (
        orders_df['order_status']
        .value_counts()
        .reset_index()
        .rename(columns={
            'index': 'order_status',
            'order_status': 'order_count'
        })
    )

def customers_per_state(customers_df):
    return (
        customers_df
        .groupby('customer_state')['customer_id']
        .nunique()
        .reset_index(name='total_customers')
        .sort_values('total_customers', ascending=False)
    )

def customers_state_percentage(cust_state_df):
    total = cust_state_df['total_customers'].sum()
    df = cust_state_df.copy()
    df['percentage'] = (df['total_customers'] / total * 100).round(2)
    return df

def customer_state_statistics(cust_state_df):
    stats = {
        "mean_customers_per_state": cust_state_df['total_customers'].mean(),
        "median_customers_per_state": cust_state_df['total_customers'].median(),
        "skewness": cust_state_df['total_customers'].skew()
    }
    return stats

def revenue_per_state(orders_df, customers_df, payments_df):
    orders_customers = orders_df.merge(
        customers_df[['customer_id', 'customer_state']],
        on='customer_id',
        how='left'
    )

    full_df = orders_customers.merge(
        payments_df[['order_id', 'payment_value']],
        on='order_id',
        how='left'
    )

    revenue_state = (
        full_df
        .groupby('customer_state')['payment_value']
        .sum()
        .reset_index(name='total_revenue')
        .sort_values('total_revenue', ascending=False)
    )

    return revenue_state

"""#### Dataset Summary"""

datasets = {
    "customers": customers,
    "geolocation": geolocation,
    "order_items": order_item,
    "order_payments": order_payment,
    "order_reviews": order_review,
    "orders": orders,
    "products": products,
    "sellers": sellers,
    "product_category_translation": product_category
}

dataset_summary(datasets)

"""#### Orders Summary"""

orders_datetime_ranges(orders)

order_status_summary(orders)

order_delivery_summary(orders)

"""#### Customers Summary"""

cust_state = customers_per_state(customers)
cust_state_pct = customers_state_percentage(cust_state)

top_data(cust_state_pct, n=10)

"""#### Revenue Summary"""

revenue_state = revenue_per_state(orders, customers, order_payment)

top_data(revenue_state, n=10)

"""### Explore

#### Functions
"""

def customers_vs_revenue_per_state(customers_df, orders_df, payments_df):
    customers_state = (
        customers_df
        .groupby('customer_state')['customer_id']
        .nunique()
        .reset_index(name='total_customers')
    )

    orders_customers = orders_df.merge(
        customers_df[['customer_id', 'customer_state']],
        on='customer_id',
        how='left'
    )

    orders_payments = orders_customers.merge(
        payments_df[['order_id', 'payment_value']],
        on='order_id',
        how='left'
    )

    revenue_state = (
        orders_payments
        .groupby('customer_state')['payment_value']
        .sum()
        .reset_index(name='total_revenue')
    )

    result = customers_state.merge(
        revenue_state,
        on='customer_state',
        how='inner'
    )

    return result.sort_values('total_customers', ascending=False)

def avg_revenue_per_customer_state(customers_df, orders_df, payments_df):
    orders_customers = orders_df.merge(
        customers_df[['customer_id', 'customer_state']],
        on='customer_id',
        how='left'
    )

    full_df = orders_customers.merge(
        payments_df[['order_id', 'payment_value']],
        on='order_id',
        how='left'
    )

    agg = (
        full_df
        .groupby('customer_state')
        .agg(
            total_revenue=('payment_value', 'sum'),
            total_customers=('customer_id', 'nunique')
        )
        .reset_index()
    )

    agg['avg_revenue_per_customer'] = (
        agg['total_revenue'] / agg['total_customers']
    )

    return agg.sort_values('avg_revenue_per_customer', ascending=False)

def avg_revenue_per_order_state(customers_df, orders_df, payments_df):
    orders_customers = orders_df.merge(
        customers_df[['customer_id', 'customer_state']],
        on='customer_id',
        how='left'
    )

    full_df = orders_customers.merge(
        payments_df[['order_id', 'payment_value']],
        on='order_id',
        how='left'
    )

    agg = (
        full_df
        .groupby('customer_state')
        .agg(
            total_revenue=('payment_value', 'sum'),
            total_orders=('order_id', 'nunique')
        )
        .reset_index()
    )

    agg['avg_revenue_per_order'] = (
        agg['total_revenue'] / agg['total_orders']
    )

    return agg.sort_values('avg_revenue_per_order', ascending=False)

def prepare_delivery_review_df(orders, order_reviews):
    df = (
        orders[['order_id', 'order_purchase_timestamp', 'order_delivered_customer_date']]
        .merge(order_reviews[['order_id', 'review_score']], on='order_id', how='inner')
    )

    df = df.dropna(subset=['order_delivered_customer_date'])

    df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])
    df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])

    df['delivery_time_days'] = (
        df['order_delivered_customer_date'] - df['order_purchase_timestamp']
    ).dt.days

    return df[df['delivery_time_days'] >= 0]

"""#### Customer VS Revenue (States)"""

state_summary = customers_vs_revenue_per_state(customers, orders, order_payment)

top_data(state_summary, n=10)

"""#### Average Revenue Per Order (States)"""

avg_revenue_per_order_state = avg_revenue_per_order_state(customers, orders, order_payment)

top_data(avg_revenue_per_order_state, n=10)

"""#### Average Revenue Per Customer (States)"""

avg_rev_customer = avg_revenue_per_customer_state(customers, orders, order_payment)

top_data(avg_rev_customer, n=10)

"""#### Delivery & Review"""

delivery_review = prepare_delivery_review_df(orders, order_review)

top_data(delivery_review, n=10)

delivery_review[['delivery_time_days', 'review_score']].describe()

"""#### Insight

**Insight:**
- Sao Paulo (SP) mendominasi secara absolut, baik dari sisi jumlah pelanggan maupun total revenue.
- Lima state teratas (SP, RJ, MG, RS, PR) menyumbang mayoritas pelanggan dan revenue, menunjukkan konsentrasi geografis yang tinggi.

## Visualization & Explanatory Analysis

### Pertanyaan 1:

#### Functions
"""

def plot_top_states_by_customers(cust_state_df, top_n=10):
    df = (
        cust_state_df
        .sort_values('total_customers', ascending=False)
        .head(top_n)
    )
    plt.figure(figsize=(10, 6))
    plt.bar(df['customer_state'], df['total_customers'])
    plt.xlabel("State")
    plt.ylabel("Total Customers")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

def plot_top_states_by_revenue(revenue_state_df, top_n=10):
    df = (
        revenue_state_df
        .sort_values('total_revenue', ascending=False)
        .head(top_n)
    )
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.bar(df['customer_state'], df['total_revenue'] / 1_000_000)
    ax.set_xlabel("State")
    ax.set_ylabel("Total Revenue (Jutaan)")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

def plot_customers_vs_revenue(state_summary_df, highlight_states=None):
    df = state_summary_df.copy()
    df['total_revenue_million'] = df['total_revenue'] / 1_000_000
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.scatter(df['total_customers'], df['total_revenue_million'])
    ax.set_xlabel("Total Customers")
    ax.set_ylabel("Total Revenue (Jutaan)")
    if highlight_states:
        for _, row in df[df['customer_state'].isin(highlight_states)].iterrows():
            ax.text(
                row['total_customers'],
                row['total_revenue_million'],
                row['customer_state'],
                fontsize=9,
                ha='left',
                va='bottom'
            )

    plt.tight_layout()
    plt.show()

def plot_avg_revenue_per_customer(avg_rev_customer_df, top_n=5):
    df = (
        avg_rev_customer_df
        .sort_values('avg_revenue_per_customer', ascending=False)
        .head(top_n)
    )
    fig, ax = plt.subplots(figsize=(8, 5))
    ax.bar(df['customer_state'], df['avg_revenue_per_customer'])
    ax.set_xlabel("State")
    ax.set_ylabel("Avg Revenue per Customer")
    plt.tight_layout()
    plt.show()

def build_state_summary_table(
    customers_revenue_df,
    avg_rev_customer_df
):
    summary = customers_revenue_df.merge(
        avg_rev_customer_df[
            ['customer_state', 'avg_revenue_per_customer']
        ],
        on='customer_state',
        how='left'
    )
    return summary.sort_values('total_customers', ascending=False)

"""#### Top 10 States by Customer Concentration"""

plot_top_states_by_customers(cust_state)

"""Sao Paulo (SP) memiliki konsentrasi pelanggan tertinggi dan mendominasi secara signifikan dibandingkan negara bagian lain. Distribusi ini menunjukkan bahwa aktivitas e-commerce di Brazil sangat terpusat secara geografis, dengan hanya beberapa negara bagian menyumbang sebagian besar pelanggan.

#### Top 10 States by Revenue
"""

plot_top_states_by_revenue(revenue_state)

"""Distribusi total revenue menunjukkan pola yang sejalan dengan konsentrasi pelanggan, di mana negara bagian dengan jumlah pelanggan besar juga berkontribusi signifikan terhadap total pendapatan. Namun, perbedaan urutan antar negara bagian mengindikasikan variasi nilai transaksi rata-rata.

#### Customers VS Revenue
"""

plot_customers_vs_revenue(
    state_summary,
    highlight_states=['SP', 'RJ', 'MG']
)

"""Terlihat hubungan positif antara jumlah pelanggan dan total revenue. Namun, beberapa negara bagian menyimpang dari pola umum, mengindikasikan perbedaan nilai transaksi antar wilayah.

#### Average Revenue Per Customer
"""

plot_avg_revenue_per_customer(avg_rev_customer)

"""Meskipun tidak memiliki jumlah pelanggan besar, beberapa negara bagian menunjukkan nilai transaksi rata-rata per pelanggan yang lebih tinggi.

#### Ringkasan Data
"""

state_summary_table = build_state_summary_table(
    state_summary,
    avg_rev_customer
)

top_data(state_summary_table, n=10)

"""### Pertanyaan 2:

#### Functions
"""

def plot_delivery_vs_review(df):
    fig, ax = plt.subplots(figsize=(8, 5))
    ax.scatter(df['delivery_time_days'], df['review_score'], alpha=0.3)
    ax.set_xlabel("Delivery Time (days)")
    ax.set_ylabel("Review Score")
    ax.set_title("Delivery Time vs Review Score")
    plt.tight_layout()
    plt.show()

def plot_review_by_delivery_bin(df):
    df = df.copy()
    df['delivery_bin'] = pd.cut(
        df['delivery_time_days'],
        bins=[0, 7, 14, 21, 30, df['delivery_time_days'].max()],
        labels=['≤7', '8–14', '15–21', '22–30', '>30']
    )

    fig, ax = plt.subplots(figsize=(8, 5))
    df.boxplot(column='review_score', by='delivery_bin', ax=ax)
    ax.set_xlabel("Delivery Time (days)")
    ax.set_ylabel("Review Score")
    ax.set_title("Review Score by Delivery Time Group")
    plt.suptitle("")
    plt.tight_layout()
    plt.show()

"""#### Review Score vs Delivery Time"""

plot_delivery_vs_review(delivery_review)

"""#### Review Score by Delivery Time"""

plot_review_by_delivery_bin(delivery_review)

"""#### Ringkasan Data"""

delivery_review[['delivery_time_days', 'review_score']].corr(method='spearman')

"""**Insight:**
> Terdapat korelasi negatif lemah antara lama waktu pengiriman dan skor ulasan pelanggan. Hal ini menunjukkan bahwa pengiriman yang lebih lama cenderung diikuti oleh penurunan skor ulasan.

## Analisis Lanjutan (Opsional)
"""



"""## Conclusion

### Pertanyaan 1

> Negara bagian dengan konsentrasi pelanggan tertinggi di Brazil adalah Sao Paulo (SP).
SP mencatat 41.746 pelanggan, jauh melampaui negara bagian lain seperti Rio de Janeiro (RJ) dan Minas Gerais (MG). Hal ini menunjukkan bahwa basis pelanggan e-commerce sangat terkonsentrasi di wilayah tenggara Brazil, khususnya SP.

---

Distribusi Total Revenue antar Negara Bagian
- Sao Paulo (SP) juga menjadi kontributor revenue terbesar, dengan total pendapatan sekitar 5,99 juta, hampir 3 kali lipat dari RJ dan MG.
- RJ (2,14 juta) dan MG (1,87 juta) berada di posisi kedua dan ketiga, mengonfirmasi dominasi wilayah Southeast dalam aktivitas ekonomi.
- Negara bagian lain seperti RS, PR, dan SC menunjukkan kontribusi menengah, sedangkan negara bagian di luar wilayah selatan dan tenggara memberikan kontribusi revenue yang relatif kecil.

Distribusi ini sangat tidak merata, di mana sebagian besar pendapatan terkonsentrasi pada sedikit negara bagian dengan basis pelanggan besar.

---

Kesimpulan Akhir
- SP adalah pusat utama pelanggan dan revenue e-commerce di Brazil
- Distribusi revenue antar negara bagian sangat timpang
- Volume-driven states ≠ high-value states
- Strategi bisnis dapat dibedakan:
  - Scale & volume, fokus di SP, RJ, MG
  - High-value customers, eksplor negara bagian kecil dengan average spending tinggi

Kesimpulan ini menjawab langsung bahwa konsentrasi pelanggan dan revenue terbesar berada di SP, namun pola pengeluaran pelanggan bervariasi antar negara bagian dan tidak selalu sejalan dengan jumlah pelanggan.

### Pertanyaan 2

> Ya, terdapat korelasi antara lama waktu pengiriman (delivery time) dan skor ulasan pelanggan, namun korelasinya bersifat negatif dan lemah.

---

Ringkasan Temuan Utama
1. Pengiriman cepat = skor ulasan tinggi

- Pada rentang ≤7 hingga 21 hari, median skor ulasan konsisten di 5.0 (sangat puas).

- Variasi skor kecil, menandakan pengalaman pelanggan relatif stabil saat pengiriman cepat.

2. Semakin lama pengiriman = penurunan skor ulasan

- Pada rentang 22–30 hari, median skor mulai turun ke 4.0 dan sebaran ulasan menjadi lebih lebar.

- Pada pengiriman >30 hari, median skor jatuh drastis ke 1.0, dengan kuartil 75% hanya mencapai 3.0.

3. Outlier memperkuat pola negatif

- Skor 1.0 (sangat kecewa) menunjukkan jumlah pencilan terbanyak pada delivery time ekstrem (>150 hari).

- Sebaliknya, skor 5.0 hampir seluruhnya terkonsentrasi pada pengiriman ≤50 hari, dengan outlier sangat jarang.

4. Korelasi numerik mendukung pola visual

- Korelasi Spearman sebesar −0.234 mengindikasikan hubungan negatif lemah: pengiriman lebih lama cenderung diikuti skor ulasan yang lebih rendah, namun bukan satu-satunya faktor penentu kepuasan.

---

Kesimpulan Akhir
> Terdapat korelasi negatif antara lama waktu pengiriman dan skor ulasan pelanggan.
Pengiriman yang lebih cepat secara konsisten dikaitkan dengan skor ulasan yang lebih tinggi, sedangkan pengiriman yang sangat lama (>30 hari) menunjukkan penurunan signifikan pada kepuasan pelanggan. Namun, karena kekuatan korelasinya relatif lemah, waktu pengiriman bukan satu-satunya faktor yang memengaruhi skor ulasan, melainkan berinteraksi dengan faktor lain seperti kualitas produk dan layanan penjual.
"""